{
  "paragraphs": [
    {
      "text": "%pyspark\n\n# # This won\u0027t work\n# def print_rdd(rdd):\n#     for x in rdd:\n#         print x\n#     print \"\"\n\n# Create a helper function for displaying results\ndef print_rdd(rdd):\n    for x in rdd.collect():\n        print x\n    print \"\"\n    ",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 4:53:27 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1490714452413_-336553625",
      "id": "20170328-152052_1791734935",
      "dateCreated": "Mar 28, 2017 3:20:52 PM",
      "dateStarted": "Jun 7, 2017 4:53:27 AM",
      "dateFinished": "Jun 7, 2017 4:53:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Parallelize a range for loop\nrdd \u003d sc.parallelize(range(10))\nprint_rdd(rdd)",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:18:53 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d0"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490714325847_1373315936",
      "id": "20170328-151845_1969267404",
      "dateCreated": "Mar 28, 2017 3:18:45 PM",
      "dateStarted": "Jun 7, 2017 5:18:53 AM",
      "dateFinished": "Jun 7, 2017 5:18:55 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Pass in a lambda\nrdd2 \u003d rdd.map(lambda x: x*x)\nprint_rdd(rdd2)",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:19:03 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "0\n1\n4\n9\n16\n25\n36\n49\n64\n81\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d1"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490714596859_856384148",
      "id": "20170328-152316_947144741",
      "dateCreated": "Mar 28, 2017 3:23:16 PM",
      "dateStarted": "Jun 7, 2017 5:19:03 AM",
      "dateFinished": "Jun 7, 2017 5:19:03 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Use a method instead\ndef my_function(x):\n    return x*x*x\n\nrdd2 \u003d rdd.map(my_function)\nprint_rdd(rdd2)",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:19:16 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "0\n1\n8\n27\n64\n125\n216\n343\n512\n729\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d2"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490714283455_136086067",
      "id": "20170328-151803_1492887213",
      "dateCreated": "Mar 28, 2017 3:18:03 PM",
      "dateStarted": "Jun 7, 2017 5:19:16 AM",
      "dateFinished": "Jun 7, 2017 5:19:16 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Fetch only a couple of items\nprint rdd2.take(2)\nprint rdd2.first()",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:19:25 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[0, 1]\n0\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d3",
            "http://172.17.0.2:4040/jobs/job?id\u003d4"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490714648491_-1231050490",
      "id": "20170328-152408_545394834",
      "dateCreated": "Mar 28, 2017 3:24:08 PM",
      "dateStarted": "Jun 7, 2017 5:19:25 AM",
      "dateFinished": "Jun 7, 2017 5:19:25 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Sorting\nprint rdd2.sortBy(lambda x: -x).collect()\n",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:19:36 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[729, 512, 343, 216, 125, 64, 27, 8, 1, 0]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d5"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490714747146_2120097106",
      "id": "20170328-152547_778240158",
      "dateCreated": "Mar 28, 2017 3:25:47 PM",
      "dateStarted": "Jun 7, 2017 5:19:36 AM",
      "dateFinished": "Jun 7, 2017 5:19:36 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Filtering\nrdd \u003d sc.parallelize(range(1000)).map(lambda x: x * x)\nprint rdd.sortBy(lambda x: x).filter(lambda x: x \u003e 1000).take(10)\n",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:19:48 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "[1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681]\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d6"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490714874432_1125321985",
      "id": "20170328-152754_1731607543",
      "dateCreated": "Mar 28, 2017 3:27:54 PM",
      "dateStarted": "Jun 7, 2017 5:19:48 AM",
      "dateFinished": "Jun 7, 2017 5:19:49 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Join some data\nleft_data \u003d [(1, \"hello\"), (2, \"goodbye\"), (3, \"the end\")]\nright_data \u003d [(2, \"cruel world\"), (1, \"world\")]\nrdd \u003d sc.parallelize(left_data)\nrdd2 \u003d sc.parallelize(right_data)\n\nrdd3 \u003d rdd.leftOuterJoin(rdd2)\nprint_rdd(rdd3)\n",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:20:08 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "(2, (\u0027goodbye\u0027, \u0027cruel world\u0027))\n(1, (\u0027hello\u0027, \u0027world\u0027))\n(3, (\u0027the end\u0027, None))\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d7"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490725083449_1243489838",
      "id": "20170328-181803_1697233286",
      "dateCreated": "Mar 28, 2017 6:18:03 PM",
      "dateStarted": "Jun 7, 2017 5:20:08 AM",
      "dateFinished": "Jun 7, 2017 5:20:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# We can filter out the ones that didn\u0027t have a match\nrdd4 \u003d rdd3.filter(lambda x: x[1][1] is not None)\nprint_rdd(rdd4)",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:21:51 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "(2, (\u0027goodbye\u0027, \u0027cruel world\u0027))\n(1, (\u0027hello\u0027, \u0027world\u0027))\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d10"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490820430744_-217230993",
      "id": "20170329-204710_23926398",
      "dateCreated": "Mar 29, 2017 8:47:10 PM",
      "dateStarted": "Jun 7, 2017 5:21:51 AM",
      "dateFinished": "Jun 7, 2017 5:21:51 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Group some data\nrdd3 \u003d rdd.union(rdd2).groupByKey().map(lambda x: (x[0], list(x[1])))\nprint_rdd(rdd3)\n",
      "user": "anonymous",
      "dateUpdated": "Jun 7, 2017 5:21:54 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "(2, [\u0027goodbye\u0027, \u0027cruel world\u0027])\n(1, [\u0027hello\u0027, \u0027world\u0027])\n(3, [\u0027the end\u0027])\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.17.0.2:4040/jobs/job?id\u003d11"
          ],
          "interpreterSettingId": "2CJBCCPJT"
        }
      },
      "apps": [],
      "jobName": "paragraph_1490725909191_-1859951153",
      "id": "20170328-183149_282206935",
      "dateCreated": "Mar 28, 2017 6:31:49 PM",
      "dateStarted": "Jun 7, 2017 5:21:54 AM",
      "dateFinished": "Jun 7, 2017 5:21:54 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Word count using groupBy/count\nrdd \u003d sc.parallelize([\"hello\", \"hello\", \"world\", \"world\", \"world\", \"world\", \"cat\", \"cat\", \"cat\", \"dog\", \"mouse\", \"mouse\"])\nrdd2 \u003d rdd.groupBy(lambda x: x).map(lambda x: (x[0], list(x[1])))\nprint_rdd(rdd2)",
      "user": "anonymous",
      "dateUpdated": "Mar 30, 2017 12:23:55 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "(\u0027mouse\u0027, [\u0027mouse\u0027, \u0027mouse\u0027])\n(\u0027world\u0027, [\u0027world\u0027, \u0027world\u0027, \u0027world\u0027, \u0027world\u0027])\n(\u0027cat\u0027, [\u0027cat\u0027, \u0027cat\u0027, \u0027cat\u0027])\n(\u0027hello\u0027, [\u0027hello\u0027, \u0027hello\u0027])\n(\u0027dog\u0027, [\u0027dog\u0027])\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1490727036001_-1096966201",
      "id": "20170328-185036_1291934831",
      "dateCreated": "Mar 28, 2017 6:50:36 PM",
      "dateStarted": "Mar 30, 2017 12:23:55 AM",
      "dateFinished": "Mar 30, 2017 12:23:55 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n# Refer to https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/best_practices/prefer_reducebykey_over_groupbykey.html as to why you would want to use reduceByKey over groupBy/groupByKey\n# Note that with some Googling around, you can find some debate on which one to use under numerous circumstances\n# Word count using map/reduceByKey\nrdd \u003d sc.parallelize([\"hello\", \"hello\", \"world\", \"world\", \"world\", \"world\", \"cat\", \"cat\", \"cat\", \"dog\", \"mouse\", \"mouse\"])\nrdd2 \u003d rdd.map(lambda x: (x[0], 1)).reduceByKey(lambda x, y: x + y)\nprint_rdd(rdd2)\n",
      "user": "anonymous",
      "dateUpdated": "Mar 30, 2017 12:30:00 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "(\u0027c\u0027, 3)\n(\u0027m\u0027, 2)\n(\u0027w\u0027, 4)\n(\u0027h\u0027, 2)\n(\u0027d\u0027, 1)\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1490727204640_-426871535",
      "id": "20170328-185324_1727570153",
      "dateCreated": "Mar 28, 2017 6:53:24 PM",
      "dateStarted": "Mar 30, 2017 12:30:00 AM",
      "dateFinished": "Mar 30, 2017 12:30:00 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "Mar 28, 2017 7:05:00 PM",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1490727900359_-803176217",
      "id": "20170328-190500_497485549",
      "dateCreated": "Mar 28, 2017 7:05:00 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Simple Parallelization",
  "id": "2CE2PGE34",
  "angularObjects": {
    "2CK39R9B2:shared_process": [],
    "2CM9DQJSU:shared_process": [],
    "2CJ86H8M4:shared_process": [],
    "2CJBKT6AU:shared_process": [],
    "2CHKW87EH:shared_process": [],
    "2CMZUNUVE:shared_process": [],
    "2CHEVY9GP:shared_process": [],
    "2CHNHBHDM:shared_process": [],
    "2CJ8G1YR6:shared_process": [],
    "2CJPERW2P:shared_process": [],
    "2CHT14MDN:shared_process": [],
    "2CHVP6K6P:shared_process": [],
    "2CH6VJCP5:shared_process": [],
    "2CJBCCPJT:shared_process": [],
    "2CKS49SWF:shared_process": [],
    "2CHPHA64M:shared_process": [],
    "2CHZYY6QF:shared_process": [],
    "2CM9JRCXA:shared_process": []
  },
  "config": {},
  "info": {}
}